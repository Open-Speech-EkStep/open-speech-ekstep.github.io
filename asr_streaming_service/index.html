<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Create ASR using Wav2vec"><meta name=author content=Ekstep><link href=https://open-speech-ekstep.github.io/asr_streaming_service/ rel=canonical><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.2.3, mkdocs-material-7.0.6"><title>Speech Recognititon Streaming API - Vakyansh</title><link rel=stylesheet href=../assets/stylesheets/main.7a40789f.min.css><link rel=stylesheet href=../assets/stylesheets/palette.7fa14f5b.min.css><meta name=theme-color content=#4051b5><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#speech-recognition-streaming-service class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=Vakyansh class="md-header__button md-logo" aria-label=Vakyansh data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Vakyansh </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Speech Recognititon Streaming API </span> </div> </div> </div> <div class=md-header__options> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Open-Speech-EkStep title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> Open-Speech-EkStep </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../data_collection/ class="md-tabs__link md-tabs__link--active"> Developer Guides </a> </li> <li class=md-tabs__item> <a href=../CONTRIBUTING/ class=md-tabs__link> About </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=Vakyansh class="md-nav__button md-logo" aria-label=Vakyansh data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> Vakyansh </label> <div class=md-nav__source> <a href=https://github.com/Open-Speech-EkStep title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> Open-Speech-EkStep </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2> Developer Guides <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Developer Guides" data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Developer Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../data_collection/ class=md-nav__link> Data Collection Pipeine </a> </li> <li class=md-nav__item> <a href=../intelligent_data_pipelines/ class=md-nav__link> Intelligent Data Pipeline </a> </li> <li class=md-nav__item> <a href=../ulca_pipeline/ class=md-nav__link> ULCA Pipeline </a> </li> <li class=md-nav__item> <a href=../model_training/ class=md-nav__link> Model Training Pipeline </a> </li> <li class=md-nav__item> <a href=../crowdsource_platform/ class=md-nav__link> Crowdsourcing Platform </a> </li> <li class=md-nav__item> <a href=../adr/ class=md-nav__link> Architecture Decision Records </a> </li> <li class=md-nav__item> <a href=../speaker_clustering/ class=md-nav__link> Speaker Clustering </a> </li> <li class=md-nav__item> <a href=../gender_identification/ class=md-nav__link> Gender Identification </a> </li> <li class=md-nav__item> <a href=../language_identification/ class=md-nav__link> Language Identification </a> </li> <li class=md-nav__item> <a href=../punctuation_model_training/ class=md-nav__link> Punctation Model Training </a> </li> <li class=md-nav__item> <a href=../inverse_text_normalization/ class=md-nav__link> Inverse Text Normalization </a> </li> <li class=md-nav__item> <a href=../asr_model_api/ class=md-nav__link> Speech Recognititon Model API </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Speech Recognititon Streaming API <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Speech Recognititon Streaming API </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#table-of-contents class=md-nav__link> Table of Contents </a> </li> <li class=md-nav__item> <a href=#architecture-overview class=md-nav__link> Architecture Overview </a> </li> <li class=md-nav__item> <a href=#components class=md-nav__link> Components </a> <nav class=md-nav aria-label=Components> <ul class=md-nav__list> <li class=md-nav__item> <a href=#grpc-server class=md-nav__link> GRPC Server </a> </li> <li class=md-nav__item> <a href=#grpc-client class=md-nav__link> GRPC Client </a> </li> <li class=md-nav__item> <a href=#proxy-service class=md-nav__link> Proxy Service </a> <nav class=md-nav aria-label="Proxy Service"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#reason-for-using-proxy-component class=md-nav__link> Reason for using proxy component </a> </li> <li class=md-nav__item> <a href=#socketio-server class=md-nav__link> Socket.io server </a> </li> <li class=md-nav__item> <a href=#nodejs-grpc-client class=md-nav__link> Nodejs Grpc client </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#browser-client-sdk class=md-nav__link> Browser Client SDK </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-start class=md-nav__link> Quick Start </a> <nav class=md-nav aria-label="Quick Start"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pre-requisites class=md-nav__link> Pre-requisites </a> </li> <li class=md-nav__item> <a href=#streaming-server-setup class=md-nav__link> Streaming server setup </a> </li> <li class=md-nav__item> <a href=#streaming-proxy-service-setup class=md-nav__link> Streaming proxy service setup </a> </li> <li class=md-nav__item> <a href=#website-ui-setup-with-streaming-client-sdk class=md-nav__link> Website UI setup with Streaming client sdk </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tips class=md-nav__link> Tips </a> </li> <li class=md-nav__item> <a href=#contribute-to-the-project class=md-nav__link> Contribute to the project </a> </li> <li class=md-nav__item> <a href=#license class=md-nav__link> License </a> </li> <li class=md-nav__item> <a href=#git-repositories class=md-nav__link> Git repositories </a> </li> <li class=md-nav__item> <a href=#contact class=md-nav__link> Contact </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tts_model_training/ class=md-nav__link> Text To Speech Model training </a> </li> <li class=md-nav__item> <a href=../tts_model_api/ class=md-nav__link> Text To Speech Model API </a> </li> <li class=md-nav__item> <a href=../api_deployment/ class=md-nav__link> API Deployment Guide </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> About <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=About data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> About </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CONTRIBUTING/ class=md-nav__link> Contributions </a> </li> <li class=md-nav__item> <a href=../RELEASE_NOTES/ class=md-nav__link> Release notes </a> </li> <li class=md-nav__item> <a href=../LICENSE class=md-nav__link> License </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#table-of-contents class=md-nav__link> Table of Contents </a> </li> <li class=md-nav__item> <a href=#architecture-overview class=md-nav__link> Architecture Overview </a> </li> <li class=md-nav__item> <a href=#components class=md-nav__link> Components </a> <nav class=md-nav aria-label=Components> <ul class=md-nav__list> <li class=md-nav__item> <a href=#grpc-server class=md-nav__link> GRPC Server </a> </li> <li class=md-nav__item> <a href=#grpc-client class=md-nav__link> GRPC Client </a> </li> <li class=md-nav__item> <a href=#proxy-service class=md-nav__link> Proxy Service </a> <nav class=md-nav aria-label="Proxy Service"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#reason-for-using-proxy-component class=md-nav__link> Reason for using proxy component </a> </li> <li class=md-nav__item> <a href=#socketio-server class=md-nav__link> Socket.io server </a> </li> <li class=md-nav__item> <a href=#nodejs-grpc-client class=md-nav__link> Nodejs Grpc client </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#browser-client-sdk class=md-nav__link> Browser Client SDK </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-start class=md-nav__link> Quick Start </a> <nav class=md-nav aria-label="Quick Start"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pre-requisites class=md-nav__link> Pre-requisites </a> </li> <li class=md-nav__item> <a href=#streaming-server-setup class=md-nav__link> Streaming server setup </a> </li> <li class=md-nav__item> <a href=#streaming-proxy-service-setup class=md-nav__link> Streaming proxy service setup </a> </li> <li class=md-nav__item> <a href=#website-ui-setup-with-streaming-client-sdk class=md-nav__link> Website UI setup with Streaming client sdk </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tips class=md-nav__link> Tips </a> </li> <li class=md-nav__item> <a href=#contribute-to-the-project class=md-nav__link> Contribute to the project </a> </li> <li class=md-nav__item> <a href=#license class=md-nav__link> License </a> </li> <li class=md-nav__item> <a href=#git-repositories class=md-nav__link> Git repositories </a> </li> <li class=md-nav__item> <a href=#contact class=md-nav__link> Contact </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=speech-recognition-streaming-service>Speech Recognition Streaming Service<a class=headerlink href=#speech-recognition-streaming-service title="Permanent link">&para;</a></h1> <p>Our speech to text interface enables you to accurately convert speech into text using an API powered by deep learning neural network algorithms for automatic speech recognition (ASR). To know more, <a href=/asr_model_api/ >Click Here</a></p> <p>This Streaming API provides an interface to accept chunks of continuous audio stream that can be transcribed in realtime to text by using the above mentioned speech to text interface.</p> <p>This service provides the following features:</p> <ul> <li> <p>Speech to text transcription support for a growing list of indic languages.</p> </li> <li> <p>Transcribe your content in real time from stored files or audio bytes.</p> </li> </ul> <p>The Developer documentation provides you with a complete set of guidelines which you need to get started with.</p> <h2 id=table-of-contents>Table of Contents<a class=headerlink href=#table-of-contents title="Permanent link">&para;</a></h2> <ul> <li><a href=#architecture-overview>Architecture overview</a></li> <li><a href=#components>Components</a><ul> <li><a href=#GRPC-Server>Grpc Server</a></li> <li><a href=#GRPC-Client>Grpc Client</a></li> <li><a href=#Proxy-Service>Proxy Service</a><ul> <li><a href=#Reason-for-using-proxy-component>Reason for using proxy component</a></li> <li><a href=#Socket.io-server>Socket.io server</a></li> <li><a href=#Nodejs-Grpc-client>Nodejs Grpc client</a></li> </ul> </li> <li><a href=#Browser-Client-SDK>Browser Client SDK</a></li> </ul> </li> <li><a href=#quick-start>Quick Start</a><ul> <li><a href=#pre-requisites>Pre-requisites</a></li> <li><a href=#streaming-server-setup>Streaming server setup</a></li> <li><a href=#streaming-proxy-service-setup>Streaming proxy server setup</a></li> <li><a href=#website-ui-setup-with-streaming-client-sdk>Website UI setup with streaming client sdk</a></li> </ul> </li> <li><a href=#tips>Tips</a></li> <li><a href=#contribute-to-the-project>Contribute to the project</a></li> <li><a href=#license>License</a></li> <li><a href=#git-repositories>Git Repositories</a></li> <li><a href=#contact>Contact</a></li> </ul> <h2 id=architecture-overview>Architecture Overview<a class=headerlink href=#architecture-overview title="Permanent link">&para;</a></h2> <p><img alt=Screenshot src=../img/streaming-service.jpg></p> <h2 id=components>Components<a class=headerlink href=#components title="Permanent link">&para;</a></h2> <p>This service consists of two main components.</p> <ul> <li>GRPC client</li> <li>GRPC server</li> </ul> <p>It also contains two plugin/support components.</p> <ul> <li>Proxy service.</li> <li>Browser client sdk.</li> </ul> <h3 id=grpc-server>GRPC Server<a class=headerlink href=#grpc-server title="Permanent link">&para;</a></h3> <p>In this streaming service, the grpc server provides a method that supports bi-directional streaming to allow users to stream audio bytes continuously and get stream of text as output. The audio bytes provided in the stream are pre-processed and provided to the model (Speech to text model) for inferencing. As a result, we get a continuous stream of text as output for the given audio stream. This server is capable of handling multiple grpc clients and provide continuous streams of output.</p> <p>This grpc server is written in <code>python</code> programming language.</p> <p>For more info on grpc servers bi-directional streaming, refer <a href="https://grpc.io/docs/what-is-grpc/core-concepts/#:~:text=the%20client%E2%80%99s%20messages.-,Bidirectional%20streaming%20RPC,-In%20a%20bidirectional">here</a>.</p> <p>This grpc server is available in the following <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api>Github Link</a></p> <h3 id=grpc-client>GRPC Client<a class=headerlink href=#grpc-client title="Permanent link">&para;</a></h3> <p>The grpc client allows users/other platforms to connect to the grpc server through a channel and call the required RPC methods.Grpc clients are available in multiple programming languages like python, nodejs, java, etc.</p> <p>In this streaming service, we are using <code>nodejs</code> grpc client to connect with the streaming service.</p> <p>To allow users to connect to our grpc server from browsers, we have created a <code>proxy service</code> which uses <code>socket.io</code> to maintain two way connections so that audio can be streamed from the user using browsers and send it to the grpc server from the proxy using <code>nodejs</code> grpc client.</p> <h3 id=proxy-service>Proxy Service<a class=headerlink href=#proxy-service title="Permanent link">&para;</a></h3> <p>This service allows browser-users/web-applications to stream audios to the grpc server and provides the streaming transcriptions back to the browser-users/web-applications.</p> <p>It is available in the following <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api-proxy>Github Link</a>.</p> <h4 id=reason-for-using-proxy-component>Reason for using proxy component<a class=headerlink href=#reason-for-using-proxy-component title="Permanent link">&para;</a></h4> <p>To use grpc client in browsers, we need to use a library called grpc-web. To know more about why grpc-web is needed, refer <a href=https://grpc.io/blog/state-of-grpc-web/ >here</a>.</p> <p>But, in the grpc-web library, there was no support for bi-directional streaming currently when this project was developed. So we have adopted to create our proxy service to create a realtime processing environment.</p> <p>The proxy service is developed using <code>nodejs</code>.</p> <p>The components of the proxy service are:</p> <ul> <li>Socket.io server</li> <li>Nodejs Grpc client</li> </ul> <h4 id=socketio-server>Socket.io server<a class=headerlink href=#socketio-server title="Permanent link">&para;</a></h4> <p>This socket.io server create events and listens to the incoming audio streams and provides the received audio streams to the grpc client. Once the socket.io server receives the stream of transcriptions from the nodejs grpc client, it will emit <code>result</code> events to the socket.io client connected to this server.</p> <h4 id=nodejs-grpc-client>Nodejs Grpc client<a class=headerlink href=#nodejs-grpc-client title="Permanent link">&para;</a></h4> <p>This nodejs grpc client creates a channel with the grpc server for each incoming user and streams the audio through the RPC method. Once the RPC method returns the stream of transcriptions, it will provide it to the socket.io server.</p> <h3 id=browser-client-sdk>Browser Client SDK<a class=headerlink href=#browser-client-sdk title="Permanent link">&para;</a></h3> <p>To connect to the proxy and stream audio, we can use a socket.io client. Since we need to do a lot of pre-processing and maintain the socket events needed, we have created a client sdk available as a npm library.</p> <p>This client sdk can be imported in any node related frameworks such as React, angular, etc. It will provide methods to connect and stream audio to the proxy service.</p> <p><img alt=Screenshot src=../img/streaming-client-sdk.png></p> <p>To know more, refer to this <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api-client>Github link</a>.</p> <p>To get started with this Browser client sdk, refer to the Readme in the above github link.</p> <h2 id=quick-start>Quick Start<a class=headerlink href=#quick-start title="Permanent link">&para;</a></h2> <h3 id=pre-requisites>Pre-requisites<a class=headerlink href=#pre-requisites title="Permanent link">&para;</a></h3> <ol> <li>Download and install <code>docker</code>.</li> <li>Download and install <code>git</code>.</li> <li>Download latest stable version of <code>nodejs</code>.</li> </ol> <h3 id=streaming-server-setup>Streaming server setup<a class=headerlink href=#streaming-server-setup title="Permanent link">&para;</a></h3> <ol> <li> <p>Pre-built docker images are hosted on gcr.io/ekstepspeechrecognition/speech_recognition_model_api. We do not follow the latest tag, so you have to use a specific tag. You can pull the image using the command given below:</p> <div class=highlight><pre><span></span><code>docker pull gcr.io/ekstepspeechrecognition/speech_recognition_model_api:3.2.25
</code></pre></div> </li> <li> <p>Create a directory deployed_models using the command: <code>mkdir deployed_models</code></p> </li> <li>Inside deployed_models folder, create a folder for each language. eg: <code>mkdir hindi</code></li> <li>Download asr fine-tuned models and language models for the languages you need from the link given <a href=https://github.com/Open-Speech-EkStep/vakyansh-models#finetuned-asr-models-works-on-v2-hydra-branch>here</a>.</li> <li>Directory structure of <code>deployed_models/</code>:</li> </ol> <div class=highlight><pre><span></span><code>.
<span class=p>|</span>-- hindi
<span class=p>|</span>   <span class=p>|</span>-- hindi_infer.pt
<span class=p>|</span>   <span class=p>|</span>-- dict.ltr.txt
<span class=p>|</span>   <span class=p>|</span>-- lexicon.lst
<span class=p>|</span>   <span class=p>|</span>-- lm.binary
<span class=p>|</span>-- english
<span class=p>|</span>   <span class=p>|</span>-- english_infer.pt
<span class=p>|</span>   <span class=p>|</span>-- dict.ltr.txt
<span class=p>|</span>   <span class=p>|</span>-- lexicon.lst
<span class=p>|</span>   <span class=p>|</span>-- lm.binary
<span class=p>|</span>-- model_dict.json
</code></pre></div> <ol> <li>The contents of the <code>model_dict.json</code> file mentioned in above step should contain the path of the model files. For example:</li> </ol> <div class=highlight><pre><span></span><code><span class=p>{</span><span class=w></span>
<span class=w>    </span><span class=nt>&quot;en&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;path&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;/english/english_infer.pt&quot;</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;enablePunctuation&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;enableITN&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w></span>
<span class=w>    </span><span class=p>},</span><span class=w></span>
<span class=w>    </span><span class=nt>&quot;hi&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;path&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;/hindi/hindi_infer.pt&quot;</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;enablePunctuation&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=nt>&quot;enableITN&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w></span>
<span class=w>    </span><span class=p>}</span><span class=w></span>
<span class=p>}</span><span class=w></span>
</code></pre></div> <p><strong>Note:</strong> <code>enablePunctuation</code> flag is used if the transcription from the model needs to be punctuated. <code>enabledITN</code> flag is used if the inverse text normalization is needed for the transcripts from the model. Streaming text from server will not have the response punctuated or ITN applied. It needs to be done separately. Refer, streaming client sdk readme for more details.</p> <ol> <li>Run the streaming grpc server using the following command:</li> </ol> <div class=highlight><pre><span></span><code>docker run -itd -p <span class=m>50051</span>:50051  --env <span class=nv>gpu</span><span class=o>=</span>True --env <span class=nv>languages</span><span class=o>=[</span><span class=s1>&#39;en&#39;</span><span class=o>]</span> --gpus all -v /home/user/project/deployed_models/:/opt/speech_recognition_open_api/deployed_models/ gcr.io/ekstepspeechrecognition/speech_recognition_model_api:3.2.25
</code></pre></div> <ol> <li>This will keep the streaming grpc server up and running in port <code>50051</code> as mentioned in the above docker command.</li> </ol> <h3 id=streaming-proxy-service-setup>Streaming proxy service setup<a class=headerlink href=#streaming-proxy-service-setup title="Permanent link">&para;</a></h3> <ol> <li>Clone the proxy service from github:</li> </ol> <div class=highlight><pre><span></span><code>git clone https://github.com/Open-Speech-EkStep/speech-recognition-open-api-proxy.git
</code></pre></div> <ol> <li>Run <code>cd speech-recognition-open-api-proxy</code>.</li> <li>Install the project dependencies: <code>npm i</code>.</li> <li>Configure the <code>language_map.json</code> file (in <code>project-root-folder</code> eg: /users/node/speech-recognition-open-api-proxy/language_map.json), so that it points to the grpc server which is hosted in port <code>50051</code> in the above steps. For example:</li> </ol> <div class=highlight><pre><span></span><code><span class=p>{</span><span class=w></span>
<span class=w>    </span><span class=nt>&quot;&lt;ip-address/host&gt;:&lt;port&gt;&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=w></span>
<span class=w>        </span><span class=s2>&quot;hi&quot;</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=s2>&quot;en&quot;</span><span class=w></span>
<span class=w>    </span><span class=p>],</span><span class=w></span>
<span class=w>    </span><span class=nt>&quot;localhost:50051&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=w></span>
<span class=w>        </span><span class=s2>&quot;ta&quot;</span><span class=p>,</span><span class=w></span>
<span class=w>        </span><span class=s2>&quot;te&quot;</span><span class=w></span>
<span class=w>    </span><span class=p>]</span><span class=w></span>
<span class=p>}</span><span class=w></span>
</code></pre></div> <ol> <li>Set the folder path of language_map.json as env variable <code>config_base_path="&lt;project-root-folder&gt;"</code>(eg: /users/node/speech-recognition-open-api-proxy).</li> <li>Run the proxy service: <code>npm start</code>.</li> <li>The proxy service will be up and running in port <code>9009</code>.</li> </ol> <h3 id=website-ui-setup-with-streaming-client-sdk>Website UI setup with Streaming client sdk<a class=headerlink href=#website-ui-setup-with-streaming-client-sdk title="Permanent link">&para;</a></h3> <ol> <li>To create a streaming web ui, clone the below repository from github:</li> </ol> <div class=highlight><pre><span></span><code>git clone https://github.com/Open-Speech-EkStep/speech-recognition-open-api-client.git
</code></pre></div> <ol> <li>Run <code>cd speech-recognition-open-api-client &amp;&amp; cd examples/react-example</code>.</li> <li>Install the project dependencies: <code>npm i</code>.</li> <li>Open the file : <code>src/App.js</code>.</li> <li>In this file, in handleStart() method in line 25 and 26, modify the url and language as you need: example</li> </ol> <div class=highlight><pre><span></span><code>  <span class=kd>const</span> <span class=nx>url</span> <span class=o>=</span> <span class=s1>&#39;http://localhost:9009&#39;</span><span class=p>;</span> <span class=c1>// url of the proxy service</span>
  <span class=kd>const</span> <span class=nx>language</span> <span class=o>=</span> <span class=s1>&#39;hi&#39;</span><span class=p>;</span> <span class=c1>// this can be en, gu depends on what models you have hosted.</span>
</code></pre></div> <ol> <li>Save and Close the file once the changes are done.</li> <li>Run the service using <code>npm start</code>.</li> <li>This will open a browser where you can click on the start button and start speaking. For every pause you provide, you will be getting a streamed transcription output.</li> </ol> <h2 id=tips>Tips<a class=headerlink href=#tips title="Permanent link">&para;</a></h2> <ol> <li>In step 7, multiple languages can be given in one docker container by doing the following for languages env variable.</li> </ol> <div class=highlight><pre><span></span><code>--env <span class=nv>languages</span><span class=o>=[</span><span class=s1>&#39;en&#39;</span>, <span class=s1>&#39;hi&#39;</span><span class=o>]</span>
</code></pre></div> <ol> <li>Multiple docker containers can be created with different language sets and they can all be accessed by using the proxy service. For example, docker container1 is hosted with en,hi on port 50051 and docker container2 is hosted with ta,te on port 50052, then <code>language_config.json</code> file content will be as follows:</li> </ol> <div class=highlight><pre><span></span><code><span class=o>{</span>
    <span class=s2>&quot;localhost:50051&quot;</span>: <span class=o>[</span>
        <span class=s2>&quot;hi&quot;</span>,
        <span class=s2>&quot;en&quot;</span>
    <span class=o>]</span>,
    <span class=s2>&quot;localhost:50052&quot;</span>: <span class=o>[</span>
        <span class=s2>&quot;ta&quot;</span>,
        <span class=s2>&quot;te&quot;</span>
    <span class=o>]</span>,
<span class=o>}</span>
</code></pre></div> <ol> <li>Port of the proxy service can be changed <code>PORT</code> env variable.</li> </ol> <h2 id=contribute-to-the-project>Contribute to the project<a class=headerlink href=#contribute-to-the-project title="Permanent link">&para;</a></h2> <p>Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are <strong>greatly appreciated</strong>.</p> <ol> <li>Fork the Project.</li> <li>Create your Feature Branch (<code>git checkout -b feature/AmazingFeature</code>).</li> <li>Commit your Changes (<code>git commit -m 'Add some AmazingFeature'</code>).</li> <li>Push to the Branch (<code>git push origin feature/AmazingFeature</code>).</li> <li>Open a Pull Request.</li> </ol> <h2 id=license>License<a class=headerlink href=#license title="Permanent link">&para;</a></h2> <p>Distributed under the [MIT] License. See <code>LICENSE</code> for more information.</p> <h2 id=git-repositories>Git repositories<a class=headerlink href=#git-repositories title="Permanent link">&para;</a></h2> <ol> <li>Streaming Server : <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api.git>https://github.com/Open-Speech-EkStep/speech-recognition-open-api.git</a>.</li> <li>Proxy Service: <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api-proxy.git>https://github.com/Open-Speech-EkStep/speech-recognition-open-api-proxy.git</a>.</li> <li>Client SDK: <a href=https://github.com/Open-Speech-EkStep/speech-recognition-open-api-client.git>https://github.com/Open-Speech-EkStep/speech-recognition-open-api-client.git</a>.</li> </ol> <h2 id=contact>Contact<a class=headerlink href=#contact title="Permanent link">&para;</a></h2> <p>Connect with community on <a href="https://gitter.im/Vakyansh/community?utm_source=share-link&utm_medium=link&utm_campaign=share-link">Gitter</a>.</p> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../asr_model_api/ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Speech Recognititon Model API </div> </div> </a> <a href=../tts_model_training/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Text To Speech Model training </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2021 EkStep Foundation. All Rights Reserved. </div> <!--         Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a> --> Vakyansh </div> <!--        --> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.sections", "navigation.tabs"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script> <script src=../assets/javascripts/bundle.7865d441.min.js></script> </body> </html>