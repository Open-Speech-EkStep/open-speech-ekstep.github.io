<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Create ASR using Wav2vec"><meta name=author content=Ekstep><link href=https://open-speech-ekstep.github.io/tts_model_training/ rel=canonical><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.2.3, mkdocs-material-7.0.6"><title>Text To Speech Model training - Vakyansh</title><link rel=stylesheet href=../assets/stylesheets/main.7a40789f.min.css><link rel=stylesheet href=../assets/stylesheets/palette.7fa14f5b.min.css><meta name=theme-color content=#4051b5><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){var e;this.value&&(e=document.location.pathname,ga("send","pageview",e+"?q="+this.value))}),"undefined"!=typeof location$&&location$.subscribe(function(e){ga("send","pageview",e.pathname)})})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#vakyansh-tts class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=Vakyansh class="md-header__button md-logo" aria-label=Vakyansh data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Vakyansh </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Text To Speech Model training </span> </div> </div> </div> <div class=md-header__options> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Open-Speech-EkStep title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> Open-Speech-EkStep </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../data_collection/ class="md-tabs__link md-tabs__link--active"> Developer Guides </a> </li> <li class=md-tabs__item> <a href=../CONTRIBUTING/ class=md-tabs__link> About </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=Vakyansh class="md-nav__button md-logo" aria-label=Vakyansh data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> Vakyansh </label> <div class=md-nav__source> <a href=https://github.com/Open-Speech-EkStep title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> Open-Speech-EkStep </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2> Developer Guides <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Developer Guides" data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Developer Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../data_collection/ class=md-nav__link> Data Collection Pipeine </a> </li> <li class=md-nav__item> <a href=../intelligent_data_pipelines/ class=md-nav__link> Intelligent Data Pipeline </a> </li> <li class=md-nav__item> <a href=../model_training/ class=md-nav__link> Model Training Pipeline </a> </li> <li class=md-nav__item> <a href=../crowdsource_platform/ class=md-nav__link> Crowdsourcing Platform </a> </li> <li class=md-nav__item> <a href=../adr/ class=md-nav__link> Architecture Decision Records </a> </li> <li class=md-nav__item> <a href=../speaker_clustering/ class=md-nav__link> Speaker Clustering </a> </li> <li class=md-nav__item> <a href=../gender_identification/ class=md-nav__link> Gender Identification </a> </li> <li class=md-nav__item> <a href=../language_identification/ class=md-nav__link> Language Identification </a> </li> <li class=md-nav__item> <a href=../asr_model_api/ class=md-nav__link> Speech Recognititon Model API </a> </li> <li class=md-nav__item> <a href=../asr_streaming_service/ class=md-nav__link> Speech Recognititon Streaming API </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Text To Speech Model training <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Text To Speech Model training </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#models class=md-nav__link> Models </a> </li> <li class=md-nav__item> <a href=#components class=md-nav__link> Components </a> </li> <li class=md-nav__item> <a href=#training-logs class=md-nav__link> Training logs </a> <nav class=md-nav aria-label="Training logs"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensorboard-logs class=md-nav__link> Tensorboard Logs </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#1-installation-and-setup-for-training class=md-nav__link> 1. Installation and Setup for training </a> </li> <li class=md-nav__item> <a href=#2-data-resampling class=md-nav__link> 2. Data Resampling </a> </li> <li class=md-nav__item> <a href=#3-spectogram-training-glow-tts class=md-nav__link> 3. Spectogram Training (glow-tts) </a> <nav class=md-nav aria-label="3. Spectogram Training (glow-tts)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-data-preparation class=md-nav__link> 3.1 Data Preparation </a> </li> <li class=md-nav__item> <a href=#32-training-glow-tts class=md-nav__link> 3.2 Training glow-tts </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-vocoder-training-hifi-gan class=md-nav__link> 4. Vocoder Training (hifi-gan) </a> <nav class=md-nav aria-label="4. Vocoder Training (hifi-gan)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-data-preparation class=md-nav__link> 4.1 Data Preparation </a> </li> <li class=md-nav__item> <a href=#42-training-hifi-gan class=md-nav__link> 4.2 Training hifi-gan </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-inference class=md-nav__link> 5. Inference </a> <nav class=md-nav aria-label="5. Inference"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-using-gradio class=md-nav__link> 5.1 Using Gradio </a> </li> <li class=md-nav__item> <a href=#52-using-fast-api class=md-nav__link> 5.2 Using fast API </a> </li> <li class=md-nav__item> <a href=#53-direct-inference-using-text class=md-nav__link> 5.3 Direct Inference using text </a> </li> <li class=md-nav__item> <a href=#54-installation-of-tts_infer-package class=md-nav__link> 5.4 Installation of tts_infer package </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tts_model_api/ class=md-nav__link> Text To Speech Model API </a> </li> <li class=md-nav__item> <a href=../api_deployment/ class=md-nav__link> API Deployment Guide </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> About <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=About data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> About </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CONTRIBUTING/ class=md-nav__link> Contributions </a> </li> <li class=md-nav__item> <a href=../RELEASE_NOTES/ class=md-nav__link> Release notes </a> </li> <li class=md-nav__item> <a href=../LICENSE class=md-nav__link> License </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#models class=md-nav__link> Models </a> </li> <li class=md-nav__item> <a href=#components class=md-nav__link> Components </a> </li> <li class=md-nav__item> <a href=#training-logs class=md-nav__link> Training logs </a> <nav class=md-nav aria-label="Training logs"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensorboard-logs class=md-nav__link> Tensorboard Logs </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#1-installation-and-setup-for-training class=md-nav__link> 1. Installation and Setup for training </a> </li> <li class=md-nav__item> <a href=#2-data-resampling class=md-nav__link> 2. Data Resampling </a> </li> <li class=md-nav__item> <a href=#3-spectogram-training-glow-tts class=md-nav__link> 3. Spectogram Training (glow-tts) </a> <nav class=md-nav aria-label="3. Spectogram Training (glow-tts)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-data-preparation class=md-nav__link> 3.1 Data Preparation </a> </li> <li class=md-nav__item> <a href=#32-training-glow-tts class=md-nav__link> 3.2 Training glow-tts </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-vocoder-training-hifi-gan class=md-nav__link> 4. Vocoder Training (hifi-gan) </a> <nav class=md-nav aria-label="4. Vocoder Training (hifi-gan)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-data-preparation class=md-nav__link> 4.1 Data Preparation </a> </li> <li class=md-nav__item> <a href=#42-training-hifi-gan class=md-nav__link> 4.2 Training hifi-gan </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-inference class=md-nav__link> 5. Inference </a> <nav class=md-nav aria-label="5. Inference"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-using-gradio class=md-nav__link> 5.1 Using Gradio </a> </li> <li class=md-nav__item> <a href=#52-using-fast-api class=md-nav__link> 5.2 Using fast API </a> </li> <li class=md-nav__item> <a href=#53-direct-inference-using-text class=md-nav__link> 5.3 Direct Inference using text </a> </li> <li class=md-nav__item> <a href=#54-installation-of-tts_infer-package class=md-nav__link> 5.4 Installation of tts_infer package </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=vakyansh-tts>vakyansh-tts<a class=headerlink href=#vakyansh-tts title="Permanent link">&para;</a></h1> <h2 id=models>Models<a class=headerlink href=#models title="Permanent link">&para;</a></h2> <p>Our open-sourced TTS models for Indic languages are present in this <a href=https://github.com/Open-Speech-EkStep/vakyansh-models>repo</a>.</p> <h2 id=components>Components<a class=headerlink href=#components title="Permanent link">&para;</a></h2> <p>There are two models at work that convert your text to an audio. First of all, we train a glow-TTS text-to-mel model to convert text to mel spectrogram. This mel spectrogram is then passed as input to a mel-to-wav model (HiFi-GAN) which converts it to an audio.</p> <ol> <li> <p>Text to Mel: We use <em>Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</em> proposed <a href=https://arxiv.org/abs/2005.11129>here</a>. You can find the original source code implemented by the authors <a href=https://github.com/jaywalnut310/glow-tts>here</a>.</p> <p><img alt=glow src=../img/glow_training_and_inference.png> <p align=center></p> <p></p> <p align=center> </p></p> </li> <li> <p>Mel to Wav: We use <em>HiFi-GAN: a GAN-based model capable of generating high fidelity speech efficiently</em> proposed <a href=https://arxiv.org/abs/2010.05646>here</a>. You can find the original source code implemented by the authors <a href=https://github.com/jik876/hifi-gan>here</a>.</p> <p><img alt=hifi src=../img/hifi_GAN.png> <p align=center></p> <p></p> <p align=center> </p></p> </li> </ol> <h2 id=training-logs>Training logs<a class=headerlink href=#training-logs title="Permanent link">&para;</a></h2> <p><em>Language</em>: Hindi</p> <p><em>Data used for training</em>: Monolingual Hindi male corpus (4.5 hrs) from <a href=https://www.iitm.ac.in/donlab/tts/database.php>IndicCorp</a>. </p> <p><em>Sample Rate</em>: 22050 Hz</p> <p><em>Glow-TTS trained for</em>: 100 epochs <em>Hifi-GAN trained for</em>: 200k steps</p> <h3 id=tensorboard-logs>Tensorboard Logs<a class=headerlink href=#tensorboard-logs title="Permanent link">&para;</a></h3> <p><img alt="glow logs" src=../img/glow_hi_male_logs.png></p> <p align=center> </p> <p align=center> <i>Logs for Glow-TTS training</i> </p> <p><img alt="hifi logs" src=../img/hifi_hi_male_logs.png></p> <p align=center> </p> <p align=center> <i>Logs for Hifi GAN training</i> </p> <h2 id=1-installation-and-setup-for-training>1. Installation and Setup for training<a class=headerlink href=#1-installation-and-setup-for-training title="Permanent link">&para;</a></h2> <p>Clone repo <div class=highlight><pre><span></span><code>git clone https://github.com/Open-Speech-EkStep/vakyansh-tts
</code></pre></div> Note: If you're interested in training a multi-speaker glow-tts for Text to Mel conversion, you can clone the <em>multispeaker</em> branch from <a href=https://github.com/Open-Speech-EkStep/vakyansh-tts/tree/multispeaker>here</a> or:</p> <div class=highlight><pre><span></span><code>git clone https://github.com/Open-Speech-EkStep/vakyansh-tts -b multispeaker
</code></pre></div> <p>Build conda virtual environment <div class=highlight><pre><span></span><code>cd ./vakyansh-tts
conda create --name &lt;env_name&gt; python=3.7
conda activate &lt;env_name&gt;
pip install -r requirements.txt
</code></pre></div> Install <a href=https://github.com/NVIDIA/apex>apex</a>; commit: 37cdaf4 for Mixed-precision training</p> <p>Note: this is needed for glow-tts training <div class=highlight><pre><span></span><code>cd ..
git clone https://github.com/NVIDIA/apex
cd apex
git checkout 37cdaf4
pip install -v --disable-pip-version-check --no-cache-dir ./
cd ../vakyansh-tts
</code></pre></div> Build Monotonic Alignment Search Code (Cython) <div class=highlight><pre><span></span><code>bash install.sh
</code></pre></div></p> <h2 id=2-data-resampling>2. Data Resampling<a class=headerlink href=#2-data-resampling title="Permanent link">&para;</a></h2> <p>The data format should have a folder containing all the .wav files for glow-tts and a text file containing filenames with their sentences.</p> <p>Directory structure: </p> <p>langauge_folder_name <div class=highlight><pre><span></span><code>language_folder_name
|-- ./wav/*.wav
|-- ./text_file_name.txt
</code></pre></div> The format for text_file_name.txt (Text file is only needed for glow-tts training)</p> <div class=highlight><pre><span></span><code>( audio1.wav &quot;Sentence1.&quot; )
( audio2.wav &quot;Sentence2.&quot; )
</code></pre></div> <p>To resample the .wav files to 22050 sample rate, change the following parameters in the vakyansh-tts/scripts/data/resample.sh</p> <div class=highlight><pre><span></span><code>input_wav_path : absolute path to wav file folder in vakyansh_tts/data/
output_wav_path : absolute path to vakyansh_tts/data/resampled_wav_folder_name
output_sample_rate : 22050 (or any other desired sample rate)
</code></pre></div> <p>To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/data/
bash resample.sh
</code></pre></div></p> <h2 id=3-spectogram-training-glow-tts>3. Spectogram Training (glow-tts)<a class=headerlink href=#3-spectogram-training-glow-tts title="Permanent link">&para;</a></h2> <h3 id=31-data-preparation>3.1 Data Preparation<a class=headerlink href=#31-data-preparation title="Permanent link">&para;</a></h3> <p>To prepare the data edit the vakyansh-tts/scripts/glow/prepare_data.sh file and change the following parameters <div class=highlight><pre><span></span><code>input_text_path : absolute path to vakyansh_tts/data/text_file_name.txt
input_wav_path : absolute path to vakyansh_tts/data/resampled_wav_folder_name
gender : female or male voice
</code></pre></div> To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/glow/
bash prepare_data.sh
</code></pre></div></p> <h3 id=32-training-glow-tts>3.2 Training glow-tts<a class=headerlink href=#32-training-glow-tts title="Permanent link">&para;</a></h3> <p>To start the spectogram-training edit the vakyansh-tts/scripts/glow/train_glow.sh file and change the following parameter: <div class=highlight><pre><span></span><code>gender : female or male voice
</code></pre></div> Make sure that the gender is same as that of the prepare_data.sh file</p> <p>To start the training, run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/glow/
bash train_glow.sh
</code></pre></div></p> <h2 id=4-vocoder-training-hifi-gan>4. Vocoder Training (hifi-gan)<a class=headerlink href=#4-vocoder-training-hifi-gan title="Permanent link">&para;</a></h2> <h3 id=41-data-preparation>4.1 Data Preparation<a class=headerlink href=#41-data-preparation title="Permanent link">&para;</a></h3> <p>To prepare the data edit the vakyansh-tts/scripts/hifi/prepare_data.sh file and change the following parameters <div class=highlight><pre><span></span><code>input_wav_path : absolute path to vakyansh_tts/data/resampled_wav_folder_name
gender : female or male voice
</code></pre></div> To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/hifi/
bash prepare_data.sh
</code></pre></div></p> <h3 id=42-training-hifi-gan>4.2 Training hifi-gan<a class=headerlink href=#42-training-hifi-gan title="Permanent link">&para;</a></h3> <p>To start the spectogram-training edit the vakyansh-tts/scripts/hifi/train_hifi.sh file and change the following parameter: <div class=highlight><pre><span></span><code>gender : female or male voice
</code></pre></div> Make sure that the gender is same as that of the prepare_data.sh file</p> <p>To start the training, run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/hifi/
bash train_hifi.sh
</code></pre></div></p> <h2 id=5-inference>5. Inference<a class=headerlink href=#5-inference title="Permanent link">&para;</a></h2> <h3 id=51-using-gradio>5.1 Using Gradio<a class=headerlink href=#51-using-gradio title="Permanent link">&para;</a></h3> <p>To use the gradio link edit the following parameters in the vakyansh-tts/scripts/inference/gradio.sh file: <div class=highlight><pre><span></span><code>gender : female or male voice
device : cpu or cuda
lang : langauge code
</code></pre></div></p> <p>To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/inference/
bash gradio.sh
</code></pre></div></p> <h3 id=52-using-fast-api>5.2 Using fast API<a class=headerlink href=#52-using-fast-api title="Permanent link">&para;</a></h3> <p>To use the fast api link edit the parameters in the vakyansh-tts/scripts/inference/api.sh file similar to section 5.1</p> <p>To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/inference/
bash api.sh
</code></pre></div></p> <h3 id=53-direct-inference-using-text>5.3 Direct Inference using text<a class=headerlink href=#53-direct-inference-using-text title="Permanent link">&para;</a></h3> <p>To infer, edit the parameters in the vakyansh-tts/scripts/inference/infer.sh file similar to section 5.1 and set the text to the text variable</p> <p>To run:<br> <div class=highlight><pre><span></span><code><span class=nb>cd</span> scripts/inference/
bash infer.sh
</code></pre></div></p> <p>To configure other parameters there is a version that runs the advanced inference as well. Additional Parameters: <div class=highlight><pre><span></span><code>noise_scale : can vary from 0 to 1 for noise factor
length_scale : can vary from 0 to 2 for changing the speed of the generated audio 
transliteration : whether to switch on/off transliteration. 1: ON, 0: OFF
number_conversion : whether to switch on/off number to words conversion. 1: ON, 0: OFF
split_sentences : whether to switch on/off splitting of sentences. 1: ON, 0: OFF
</code></pre></div> To run: <div class=highlight><pre><span></span><code>cd scripts/inference/
bash advanced_infer.sh
</code></pre></div></p> <h3 id=54-installation-of-tts_infer-package>5.4 Installation of tts_infer package<a class=headerlink href=#54-installation-of-tts_infer-package title="Permanent link">&para;</a></h3> <p>In tts_infer package, we currently have two components:</p> <div class=highlight><pre><span></span><code>1. Transliteration (AI4bharat&#39;s open sourced models) (Languages supported: {&#39;hi&#39;, &#39;gu&#39;, &#39;mr&#39;, &#39;bn&#39;, &#39;te&#39;, &#39;ta&#39;, &#39;kn&#39;, &#39;pa&#39;, &#39;gom&#39;, &#39;mai&#39;, &#39;ml&#39;, &#39;sd&#39;, &#39;si&#39;, &#39;ur&#39;} )

2. Num to Word (Languages supported: {&#39;en&#39;, &#39;hi&#39;, &#39;gu&#39;, &#39;mr&#39;, &#39;bn&#39;, &#39;te&#39;, &#39;ta&#39;, &#39;kn&#39;, &#39;or&#39;, &#39;pa&#39;} )
</code></pre></div> <p><code>git clone https://github.com/Open-Speech-EkStep/vakyansh-tts cd vakyansh-tts bash install.sh python setup.py bdist_wheel pip install -e . cd tts_infer gsutil -m cp -r gs://vakyaansh-open-models/translit_models .</code></p> <p>Usage: Refer to example file in tts_infer/ <div class=highlight><pre><span></span><code>from tts_infer.tts import TextToMel, MelToWav
from tts_infer.transliterate import XlitEngine
from tts_infer.num_to_word_on_sent import normalize_nums

import re
from scipy.io.wavfile import write

text_to_mel = TextToMel(glow_model_dir=&#39;/path/to/glow-tts/checkpoint/dir&#39;, device=&#39;cuda&#39;)
mel_to_wav = MelToWav(hifi_model_dir=&#39;/path/to/hifi/checkpoint/dir&#39;, device=&#39;cuda&#39;)

def translit(text, lang):
    reg = re.compile(r&#39;[a-zA-Z]&#39;)
    engine = XlitEngine(lang)
    words = [engine.translit_word(word, topk=1)[lang][0] if reg.match(word) else word for word in text.split()]
    updated_sent = &#39; &#39;.join(words)
    return updated_sent

def run_tts(text, lang):
    text = text.replace(&#39;ред&#39;, &#39;.&#39;) # only for hindi models
    text_num_to_word = normalize_nums(text, lang) # converting numbers to words in lang
    text_num_to_word_and_transliterated = translit(text_num_to_word, lang) # transliterating english words to lang

    mel = text_to_mel.generate_mel(text_num_to_word_and_transliterated)
    audio, sr = mel_to_wav.generate_wav(mel)
    write(filename=&#39;temp.wav&#39;, rate=sr, data=audio) # for saving wav file, if needed
    return (sr, audio)
</code></pre></div></p> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../asr_streaming_service/ class="md-footer__link md-footer__link--prev" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Speech Recognititon Streaming API </div> </div> </a> <a href=../tts_model_api/ class="md-footer__link md-footer__link--next" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Text To Speech Model API </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2021 EkStep Foundation. All Rights Reserved. </div> <!--         Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a> --> Vakyansh </div> <!--        --> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.sections", "navigation.tabs"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script> <script src=../assets/javascripts/bundle.7865d441.min.js></script> </body> </html>